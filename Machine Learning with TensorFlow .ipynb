{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["jLvayda9mOgo"],"authorship_tag":"ABX9TyPU7p48rQ2jfI9mV8ZqqqPI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Build hypothesis and cost"],"metadata":{"id":"N34-gZ4pzrEu"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt"],"metadata":{"id":"K-mdJmQ1zuzL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_data = [1, 2, 3, 4, 5]\n","y_data = [1, 2, 3, 4, 5]\n","\n","W = tf.Variable(2.9)\n","b = tf.Variable(0.5)\n","\n","hypothesis = W * x_data + b\n","cost = tf.reduce_mean(tf.square(hypothesis - y_data))"],"metadata":{"id":"V6MlQ2sR0A7T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- tf.reduce_mean()\n",": 차원을 줄이면서 평균을 구함."],"metadata":{"id":"YoniqOc70pRr"}},{"cell_type":"code","source":["v = [1., 2., 3., 4.]\n","tf.reduce_mean(v) # 2.5"],"metadata":{"id":"_NAkxt2F0vOS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- tf.square()\n",": ()안의 숫자를 제곱함."],"metadata":{"id":"xqX1h5yH04E7"}},{"cell_type":"code","source":["tf.square(3) #9"],"metadata":{"id":"h-ry6lx-0_D6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Cost Fuction\n",": 머신러닝은 이 Cost Fuction이 최저점이 되는 지점을 찾는 것이다."],"metadata":{"id":"jLvayda9mOgo"}},{"cell_type":"code","source":["x_data = [1, 2, 3]\n","y_data = [1, 2, 3]\n","for i in range(4):\n","    W = tf.Variable(float(i))\n","    hypothesis = W*x_data\n","    cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n","    print(\"{:5} | {:10.4f}\".format(i, cost))"],"metadata":{"id":"NY3C2-PX8JWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xxb1WiyVrC_S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Gradient descent(경사 하강 알고리즘)\n"],"metadata":{"id":"29CjtB9g1I91"}},{"cell_type":"markdown","source":["- 최초의 추정 시작\n","    - 0,0 또는 다른 랜덤값으로 지정\n","    - W와 b값을 Cost값이 조금씩 줄어들 수 있는 방향으로 지속적으로 바꿈\n","- W와 b값을 지속적으로 업데이트 할 때마다 기울기값을 구해서 Cost값이 최소화되는 방향으로 업데이트를 해나감\n","- 최소점에 도달했다고 판단될 때까지 위 과정을 반복\n"],"metadata":{"id":"yzLLo8hRpTiv"}},{"cell_type":"code","source":["learning_rate = 0.01 # 구한 기울기값(미분값)을 얼만큼 반영할 것인지를 결정\n","# learning_rate가 크면 많이 반영, learning_rate가 작으면 적게 반\n","with tf.GradientTape() as tape: # 블럭 안의 변수들의 변화정보를 테이브에 기록함.\n","    hypothesis = W * x_data + b\n","    cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n","\n","W_grad, b_grad = tape.gradient(cost, [W, b]) #cost 함수에 대해서 변수들에 대한 개별 미분값을 튜플로 반환\n","\n","W.assign_sub(learning_rate * W_grad) #  assign_sub == A = A - B or A -=B\n","b.assign_sub(learning_rate * b_grad)"],"metadata":{"id":"VDJFnwdP1Q3L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","x_data = [1, 2, 3, 4, 5]\n","y_data = [1, 2, 3, 4, 5]\n","\n","W = tf.Variable(2.9)\n","b = tf.Variable(0.5)\n","\n","\n","for i in range(100):\n","    with tf.GradientTape() as tape:\n","        hypothesis = W * x_data + b\n","        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n","    W_grad, b_grad = tape.gradient(cost, [W, b])\n","    W.assign_sub(learning_rate * W_grad)\n","    b.assign_sub(learning_rate * b_grad)\n","    if i % 10 == 0 :\n","        print(\"{:5} | {:10.4f} | {:10.4f} | {:10.6f}\".format(int(i/10+1), W.numpy(), b.numpy(), cost))"],"metadata":{"id":"hIHM7kGm3lST"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(W * 5 + b)\n","print(W * 2.5 + b)"],"metadata":{"id":"QVG4GkMP4h78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = np.array([1, 2, 3])\n","Y = np.array([1, 2, 3])\n","\n","def cost_func(W, X, Y):\n","    c = 0\n","    for i in range(len(X)) :\n","        c += (W * X[i] - Y[i]) ** 2\n","    return c / len(X)\n","\n","for feed_W in np.linspace(-3, 5, num=15): # linspace 값은 -3에서 5까지 15개의 구간을 가진다.\n","    curr_cost = cost_func(feed_W, X, Y)\n","    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_cost))"],"metadata":{"id":"zUfC-E6usQtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = np.array([1, 2, 3])\n","Y = np.array([1, 2, 3])\n","\n","def cost_func(W, X, Y):\n","    hypothesis = X * W\n","    return tf.reduce_mean(tf.square(hypothesis - Y))\n","\n","W_values = np.linspace(-3, 5, num=15)\n","cost_values = []\n","\n","for feed_W in W_values:\n","    curr_cost = cost_func(feed_W, X, Y)\n","    cost_values.append(curr_cost)\n","    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_cost))"],"metadata":{"id":"AfY1olFzt6hb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.random.set_seed(0)\n","\n","x_data = [1., 2., 3., 4.]\n","y_data = [1., 3., 5., 7.]\n","\n","W = tf.Variable(tf.random.normal([1], -100., 100.))\n","\n","for step in range(300) :\n","    hypothesis = W * X\n","    cost = tf.reduce_mean(tf.square(hypothesis - Y))\n","\n","    alpha = 0.01\n","    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))\n","    descent = W - tf.multiply(alpha, gradient)\n","    W.assign(descent)\n","\n","    if step % 10 == 0 :\n","        print('{:5} | {:10.4f} | {:10.6f}'.format(step, cost.numpy(), W.numpy()[0]))"],"metadata":{"id":"DCJgcg_Cu_QC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K0GmI5UczToy"},"execution_count":null,"outputs":[]}]}